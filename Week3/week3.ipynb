{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#設置好環境\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2aa793e6290>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#準備數據集\n",
    "#定義參數\n",
    "n_epochs = 3\n",
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "log_interval = 10\n",
    "random_seed = 1\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('./data/', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_train, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('./data/', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_test, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 9, 4, 9, 9, 0, 8, 3, 1, 2, 3, 9, 1, 3, 6, 6, 4, 4, 9, 7, 3, 7, 6, 3,\n",
      "        4, 8, 4, 6, 8, 6, 1, 1, 1, 1, 0, 0, 1, 8, 4, 0, 1, 2, 7, 9, 3, 2, 3, 8,\n",
      "        3, 2, 0, 4, 6, 6, 5, 5, 3, 0, 3, 7, 2, 4, 1, 6, 7, 5, 4, 1, 0, 8, 5, 9,\n",
      "        0, 9, 6, 1, 8, 0, 9, 3, 5, 7, 8, 5, 6, 4, 2, 2, 2, 1, 8, 4, 4, 2, 1, 5,\n",
      "        9, 3, 7, 0, 4, 1, 7, 2, 2, 6, 5, 1, 2, 6, 1, 3, 1, 2, 7, 4, 1, 3, 2, 9,\n",
      "        3, 7, 2, 7, 4, 7, 0, 0, 9, 0, 9, 5, 1, 6, 9, 8, 1, 4, 6, 7, 5, 5, 6, 4,\n",
      "        5, 4, 0, 7, 4, 1, 3, 8, 2, 6, 2, 2, 8, 4, 1, 9, 6, 7, 5, 0, 7, 4, 6, 2,\n",
      "        6, 8, 7, 9, 8, 0, 7, 4, 2, 4, 9, 0, 4, 6, 5, 6, 6, 4, 4, 8, 3, 8, 0, 9,\n",
      "        5, 6, 3, 3, 8, 4, 4, 6, 7, 8, 5, 3, 4, 3, 3, 3, 3, 1, 8, 8, 9, 1, 0, 1,\n",
      "        4, 1, 0, 2, 0, 6, 5, 1, 5, 8, 8, 1, 3, 9, 4, 5, 9, 2, 5, 6, 5, 8, 2, 7,\n",
      "        4, 1, 6, 8, 7, 9, 3, 3, 4, 4, 5, 4, 9, 8, 2, 9, 1, 6, 7, 1, 0, 5, 1, 9,\n",
      "        2, 1, 5, 2, 7, 9, 0, 0, 6, 0, 8, 7, 2, 6, 1, 7, 6, 1, 2, 1, 6, 3, 1, 4,\n",
      "        1, 7, 5, 9, 3, 8, 6, 3, 8, 7, 4, 2, 3, 2, 4, 3, 5, 1, 2, 4, 0, 9, 4, 0,\n",
      "        5, 0, 7, 3, 3, 1, 8, 4, 1, 2, 2, 6, 0, 2, 1, 6, 3, 6, 2, 1, 7, 3, 9, 9,\n",
      "        0, 7, 6, 6, 8, 0, 1, 1, 9, 9, 6, 9, 4, 7, 8, 7, 8, 5, 3, 2, 4, 4, 3, 3,\n",
      "        1, 9, 5, 3, 1, 8, 4, 7, 6, 0, 5, 9, 7, 5, 4, 0, 3, 6, 0, 0, 5, 9, 7, 4,\n",
      "        7, 7, 3, 3, 8, 0, 5, 8, 6, 3, 4, 9, 6, 2, 2, 9, 3, 9, 4, 3, 7, 8, 0, 3,\n",
      "        7, 5, 1, 7, 0, 1, 7, 1, 6, 8, 9, 0, 2, 0, 0, 2, 8, 5, 6, 2, 1, 6, 4, 2,\n",
      "        1, 0, 7, 8, 7, 9, 8, 3, 1, 5, 2, 5, 0, 3, 8, 4, 1, 8, 0, 2, 4, 4, 0, 0,\n",
      "        4, 2, 8, 7, 5, 8, 5, 3, 7, 3, 3, 3, 1, 2, 4, 5, 9, 8, 2, 7, 6, 8, 6, 1,\n",
      "        3, 4, 0, 3, 7, 0, 3, 2, 9, 6, 2, 1, 7, 8, 1, 6, 9, 8, 6, 8, 7, 0, 5, 2,\n",
      "        5, 4, 4, 8, 6, 6, 8, 6, 7, 0, 9, 4, 4, 9, 7, 5, 7, 5, 9, 0, 8, 3, 9, 8,\n",
      "        1, 3, 3, 1, 0, 0, 1, 2, 1, 7, 0, 7, 0, 9, 8, 3, 2, 2, 0, 3, 0, 3, 0, 3,\n",
      "        6, 1, 5, 8, 8, 7, 4, 5, 2, 6, 7, 8, 4, 8, 3, 9, 2, 6, 8, 7, 2, 3, 0, 4,\n",
      "        9, 7, 7, 5, 0, 3, 6, 2, 9, 5, 9, 3, 7, 3, 6, 0, 9, 6, 5, 1, 6, 3, 9, 0,\n",
      "        9, 8, 4, 1, 6, 4, 1, 9, 1, 4, 6, 9, 4, 4, 7, 2, 3, 5, 9, 9, 2, 3, 0, 9,\n",
      "        9, 0, 0, 2, 4, 5, 6, 4, 7, 9, 0, 9, 0, 8, 3, 3, 1, 6, 0, 8, 3, 9, 8, 0,\n",
      "        3, 9, 7, 4, 8, 0, 9, 9, 7, 4, 9, 0, 1, 9, 0, 3, 3, 6, 8, 2, 6, 0, 0, 8,\n",
      "        8, 7, 9, 7, 7, 6, 1, 6, 0, 1, 9, 9, 5, 6, 9, 6, 2, 2, 1, 1, 6, 0, 7, 8,\n",
      "        4, 2, 4, 7, 0, 8, 9, 5, 9, 6, 9, 1, 2, 2, 8, 1, 3, 6, 2, 0, 5, 1, 1, 6,\n",
      "        8, 7, 0, 6, 2, 5, 6, 1, 9, 8, 6, 8, 5, 1, 7, 3, 2, 0, 9, 2, 2, 5, 5, 3,\n",
      "        8, 1, 4, 9, 7, 7, 1, 8, 2, 8, 1, 1, 7, 4, 1, 6, 9, 2, 0, 3, 4, 2, 0, 5,\n",
      "        7, 5, 7, 2, 5, 6, 8, 2, 6, 7, 3, 1, 6, 2, 4, 2, 0, 2, 5, 4, 1, 1, 5, 7,\n",
      "        4, 5, 2, 0, 8, 0, 4, 7, 3, 8, 8, 2, 3, 2, 6, 5, 1, 0, 4, 1, 3, 9, 0, 2,\n",
      "        8, 9, 1, 2, 0, 8, 7, 4, 4, 0, 7, 1, 0, 8, 5, 3, 3, 3, 4, 0, 7, 4, 4, 5,\n",
      "        0, 2, 2, 7, 8, 1, 2, 8, 0, 3, 5, 4, 6, 7, 9, 0, 0, 7, 3, 9, 4, 9, 5, 1,\n",
      "        4, 4, 9, 8, 7, 3, 9, 0, 8, 7, 0, 8, 4, 5, 8, 1, 7, 4, 2, 1, 1, 5, 1, 1,\n",
      "        5, 5, 6, 4, 3, 7, 3, 3, 3, 0, 4, 7, 9, 0, 3, 9, 8, 0, 7, 8, 7, 0, 0, 3,\n",
      "        7, 7, 6, 8, 8, 9, 8, 0, 9, 4, 9, 3, 8, 6, 8, 2, 0, 4, 8, 4, 4, 4, 6, 8,\n",
      "        3, 6, 3, 5, 1, 9, 5, 4, 3, 8, 3, 1, 2, 3, 1, 1, 9, 9, 5, 5, 0, 4, 1, 6,\n",
      "        9, 4, 8, 6, 8, 1, 7, 2, 6, 9, 8, 2, 7, 2, 2, 4, 8, 9, 3, 6, 2, 2, 7, 8,\n",
      "        5, 7, 2, 0, 0, 2, 3, 1, 1, 5, 8, 5, 3, 9, 7, 6])\n",
      "torch.Size([1000, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "examples = enumerate(test_loader)\n",
    "batch_idx, (example_data, example_targets) = next(examples)\n",
    "print(example_targets)\n",
    "print(example_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(6):\n",
    "  plt.subplot(2,3,i+1)\n",
    "  plt.tight_layout()\n",
    "  plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
    "  plt.title(\"Ground Truth: {}\".format(example_targets[i]))\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Net()\n",
    "optimizer = optim.SGD(network.parameters(), lr=learning_rate,\n",
    "                      momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "test_counter = [i*len(train_loader.dataset) for i in range(n_epochs + 1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-c73b301f3a92>:16: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.319280\n",
      "Train Epoch: 1 [640/60000 (1%)]\tLoss: 2.290954\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 2.318535\n",
      "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 2.261000\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 2.259137\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 2.229576\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 2.196151\n",
      "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 2.181698\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 2.088444\n",
      "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 2.014765\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 1.818533\n",
      "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 1.822772\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 1.838733\n",
      "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 1.530556\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 1.738141\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 1.420971\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 1.369237\n",
      "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 1.335397\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 1.182360\n",
      "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 1.056649\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 1.085397\n",
      "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 1.043771\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 0.979950\n",
      "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 1.015060\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 0.934762\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.879235\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 0.789030\n",
      "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 0.978481\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 0.976565\n",
      "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 0.967663\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.968908\n",
      "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 0.949749\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.706845\n",
      "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 0.851653\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 0.641955\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.740981\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.843173\n",
      "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 0.613265\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.985883\n",
      "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 0.522866\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.723652\n",
      "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 0.715425\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.821604\n",
      "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 0.836158\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.583805\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.615134\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.799276\n",
      "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 0.420865\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.517247\n",
      "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 0.547452\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.556379\n",
      "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 0.593880\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.670385\n",
      "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 0.642911\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.430567\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.729685\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.519481\n",
      "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 0.434836\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.669772\n",
      "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 0.580954\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.589905\n",
      "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 0.511505\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.483866\n",
      "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 0.640771\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.550231\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.803255\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.540666\n",
      "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 0.564600\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.679781\n",
      "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 0.558550\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.465496\n",
      "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 0.449658\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.622232\n",
      "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 0.437512\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.488664\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.520331\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.400496\n",
      "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 0.624334\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.458803\n",
      "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 0.376350\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.650928\n",
      "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 0.414658\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.348161\n",
      "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 0.379192\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.578269\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.407332\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.451860\n",
      "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 0.379555\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.741254\n",
      "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 0.460154\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.508834\n",
      "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 0.309137\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.704712\n",
      "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.400370\n"
     ]
    }
   ],
   "source": [
    "def train(epoch):\n",
    "  network.train()\n",
    "  for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    optimizer.zero_grad()\n",
    "    output = network(data)\n",
    "    loss = F.nll_loss(output, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if batch_idx % log_interval == 0:\n",
    "      print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "        epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "        100. * batch_idx / len(train_loader), loss.item()))\n",
    "      train_losses.append(loss.item())\n",
    "      train_counter.append(\n",
    "        (batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))\n",
    "      torch.save(network.state_dict(), './model.pth')\n",
    "      torch.save(optimizer.state_dict(), './optimizer.pth')\n",
    "          \n",
    "train(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-c73b301f3a92>:16: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.1914, Accuracy: 9445/10000 (94%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def test():\n",
    "  network.eval()\n",
    "  test_loss = 0\n",
    "  correct = 0\n",
    "  with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "      output = network(data)\n",
    "      test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "      pred = output.data.max(1, keepdim=True)[1]\n",
    "      correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "  test_loss /= len(test_loader.dataset)\n",
    "  test_losses.append(test_loss)\n",
    "  print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "    test_loss, correct, len(test_loader.dataset),\n",
    "    100. * correct / len(test_loader.dataset)))\n",
    "    \n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-c73b301f3a92>:16: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.1914, Accuracy: 9445/10000 (94%)\n",
      "\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.338935\n",
      "Train Epoch: 1 [640/60000 (1%)]\tLoss: 0.369498\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 0.619978\n",
      "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 0.486589\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 0.308337\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 0.187693\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 0.443004\n",
      "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 0.478696\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 0.470186\n",
      "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 0.701200\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.491409\n",
      "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 0.362071\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 0.378886\n",
      "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 0.565268\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 0.474084\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 0.438393\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 0.299457\n",
      "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 0.581294\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 0.365953\n",
      "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 0.386954\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.527843\n",
      "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 0.409879\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 0.520775\n",
      "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 0.354869\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 0.225882\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.209931\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 0.378437\n",
      "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 0.373902\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 0.299220\n",
      "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 0.307948\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.621082\n",
      "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 0.397268\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.505620\n",
      "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 0.424988\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 0.544533\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.538535\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.454006\n",
      "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 0.308654\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.469509\n",
      "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 0.242287\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.170423\n",
      "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 0.414054\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.410475\n",
      "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 0.215819\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.226899\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.300005\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.503174\n",
      "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 0.277444\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.285906\n",
      "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 0.508989\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.638240\n",
      "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 0.434945\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.325555\n",
      "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 0.400346\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.464947\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.437218\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.466130\n",
      "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 0.369955\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.471409\n",
      "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 0.400108\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.305444\n",
      "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 0.270716\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.390275\n",
      "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 0.178860\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.464295\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.158560\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.318988\n",
      "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 0.493472\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.262175\n",
      "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 0.416058\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.300280\n",
      "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 0.454401\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.275317\n",
      "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 0.314032\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.225721\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.315971\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.336916\n",
      "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 0.502481\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.304931\n",
      "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 0.326379\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.446540\n",
      "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 0.335436\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.440017\n",
      "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 0.278519\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.216811\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.196097\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.517901\n",
      "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 0.251434\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.395251\n",
      "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 0.246394\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.529200\n",
      "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 0.463426\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.348403\n",
      "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.232751\n",
      "\n",
      "Test set: Avg. loss: 0.1235, Accuracy: 9625/10000 (96%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.249340\n",
      "Train Epoch: 2 [640/60000 (1%)]\tLoss: 0.195394\n",
      "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 0.342353\n",
      "Train Epoch: 2 [1920/60000 (3%)]\tLoss: 0.207711\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 0.201882\n",
      "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.317121\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.243186\n",
      "Train Epoch: 2 [4480/60000 (7%)]\tLoss: 0.409358\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.600000\n",
      "Train Epoch: 2 [5760/60000 (10%)]\tLoss: 0.347993\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.392487\n",
      "Train Epoch: 2 [7040/60000 (12%)]\tLoss: 0.288446\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.259840\n",
      "Train Epoch: 2 [8320/60000 (14%)]\tLoss: 0.169548\n",
      "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.286379\n",
      "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.278847\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.288852\n",
      "Train Epoch: 2 [10880/60000 (18%)]\tLoss: 0.231454\n",
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.390090\n",
      "Train Epoch: 2 [12160/60000 (20%)]\tLoss: 0.201961\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.515691\n",
      "Train Epoch: 2 [13440/60000 (22%)]\tLoss: 0.443580\n",
      "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.385693\n",
      "Train Epoch: 2 [14720/60000 (25%)]\tLoss: 0.391502\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.319024\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.817491\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.452822\n",
      "Train Epoch: 2 [17280/60000 (29%)]\tLoss: 0.414864\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.358721\n",
      "Train Epoch: 2 [18560/60000 (31%)]\tLoss: 0.272734\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.361595\n",
      "Train Epoch: 2 [19840/60000 (33%)]\tLoss: 0.409651\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.195247\n",
      "Train Epoch: 2 [21120/60000 (35%)]\tLoss: 0.235434\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.320515\n",
      "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.259495\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.434207\n",
      "Train Epoch: 2 [23680/60000 (39%)]\tLoss: 0.178515\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 0.301762\n",
      "Train Epoch: 2 [24960/60000 (42%)]\tLoss: 0.152834\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.443709\n",
      "Train Epoch: 2 [26240/60000 (44%)]\tLoss: 0.226806\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.179320\n",
      "Train Epoch: 2 [27520/60000 (46%)]\tLoss: 0.167978\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.314875\n",
      "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.629934\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 0.167902\n",
      "Train Epoch: 2 [30080/60000 (50%)]\tLoss: 0.218450\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.180907\n",
      "Train Epoch: 2 [31360/60000 (52%)]\tLoss: 0.256164\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.417889\n",
      "Train Epoch: 2 [32640/60000 (54%)]\tLoss: 0.413018\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.190403\n",
      "Train Epoch: 2 [33920/60000 (57%)]\tLoss: 0.345205\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.281634\n",
      "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.303385\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.627838\n",
      "Train Epoch: 2 [36480/60000 (61%)]\tLoss: 0.240855\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.233151\n",
      "Train Epoch: 2 [37760/60000 (63%)]\tLoss: 0.382362\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.314283\n",
      "Train Epoch: 2 [39040/60000 (65%)]\tLoss: 0.273603\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.241390\n",
      "Train Epoch: 2 [40320/60000 (67%)]\tLoss: 0.242899\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.415004\n",
      "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.346716\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.381566\n",
      "Train Epoch: 2 [42880/60000 (71%)]\tLoss: 0.223569\n",
      "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 0.277433\n",
      "Train Epoch: 2 [44160/60000 (74%)]\tLoss: 0.354480\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.168916\n",
      "Train Epoch: 2 [45440/60000 (76%)]\tLoss: 0.225711\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.346837\n",
      "Train Epoch: 2 [46720/60000 (78%)]\tLoss: 0.183950\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.476151\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.467614\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.172848\n",
      "Train Epoch: 2 [49280/60000 (82%)]\tLoss: 0.251582\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.443118\n",
      "Train Epoch: 2 [50560/60000 (84%)]\tLoss: 0.360226\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.415600\n",
      "Train Epoch: 2 [51840/60000 (86%)]\tLoss: 0.232690\n",
      "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.453515\n",
      "Train Epoch: 2 [53120/60000 (88%)]\tLoss: 0.187729\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.148717\n",
      "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.454092\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.305995\n",
      "Train Epoch: 2 [55680/60000 (93%)]\tLoss: 0.180668\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.266758\n",
      "Train Epoch: 2 [56960/60000 (95%)]\tLoss: 0.354551\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.638806\n",
      "Train Epoch: 2 [58240/60000 (97%)]\tLoss: 0.366892\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.124928\n",
      "Train Epoch: 2 [59520/60000 (99%)]\tLoss: 0.324289\n",
      "\n",
      "Test set: Avg. loss: 0.0999, Accuracy: 9676/10000 (97%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.219565\n",
      "Train Epoch: 3 [640/60000 (1%)]\tLoss: 0.159926\n",
      "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 0.291621\n",
      "Train Epoch: 3 [1920/60000 (3%)]\tLoss: 0.340421\n",
      "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 0.203409\n",
      "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.146258\n",
      "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 0.200407\n",
      "Train Epoch: 3 [4480/60000 (7%)]\tLoss: 0.312973\n",
      "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 0.242285\n",
      "Train Epoch: 3 [5760/60000 (10%)]\tLoss: 0.278312\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.197592\n",
      "Train Epoch: 3 [7040/60000 (12%)]\tLoss: 0.156746\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.327068\n",
      "Train Epoch: 3 [8320/60000 (14%)]\tLoss: 0.123948\n",
      "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 0.144768\n",
      "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.395824\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.565594\n",
      "Train Epoch: 3 [10880/60000 (18%)]\tLoss: 0.215095\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 0.242971\n",
      "Train Epoch: 3 [12160/60000 (20%)]\tLoss: 0.394666\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.122402\n",
      "Train Epoch: 3 [13440/60000 (22%)]\tLoss: 0.314529\n",
      "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 0.520093\n",
      "Train Epoch: 3 [14720/60000 (25%)]\tLoss: 0.294388\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.285816\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.080361\n",
      "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 0.177590\n",
      "Train Epoch: 3 [17280/60000 (29%)]\tLoss: 0.308590\n",
      "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 0.190550\n",
      "Train Epoch: 3 [18560/60000 (31%)]\tLoss: 0.262017\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.246063\n",
      "Train Epoch: 3 [19840/60000 (33%)]\tLoss: 0.184748\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.244457\n",
      "Train Epoch: 3 [21120/60000 (35%)]\tLoss: 0.256452\n",
      "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 0.277750\n",
      "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.153403\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.259929\n",
      "Train Epoch: 3 [23680/60000 (39%)]\tLoss: 0.128062\n",
      "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 0.161580\n",
      "Train Epoch: 3 [24960/60000 (42%)]\tLoss: 0.243873\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.185182\n",
      "Train Epoch: 3 [26240/60000 (44%)]\tLoss: 0.129375\n",
      "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 0.132852\n",
      "Train Epoch: 3 [27520/60000 (46%)]\tLoss: 0.232697\n",
      "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 0.397636\n",
      "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.183112\n",
      "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 0.261925\n",
      "Train Epoch: 3 [30080/60000 (50%)]\tLoss: 0.155176\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.234560\n",
      "Train Epoch: 3 [31360/60000 (52%)]\tLoss: 0.139012\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.252670\n",
      "Train Epoch: 3 [32640/60000 (54%)]\tLoss: 0.221178\n",
      "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 0.431637\n",
      "Train Epoch: 3 [33920/60000 (57%)]\tLoss: 0.198699\n",
      "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 0.194598\n",
      "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 0.305832\n",
      "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 0.403007\n",
      "Train Epoch: 3 [36480/60000 (61%)]\tLoss: 0.203028\n",
      "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 0.098079\n",
      "Train Epoch: 3 [37760/60000 (63%)]\tLoss: 0.306578\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.191280\n",
      "Train Epoch: 3 [39040/60000 (65%)]\tLoss: 0.293846\n",
      "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 0.181216\n",
      "Train Epoch: 3 [40320/60000 (67%)]\tLoss: 0.179883\n",
      "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.367322\n",
      "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.207294\n",
      "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 0.191219\n",
      "Train Epoch: 3 [42880/60000 (71%)]\tLoss: 0.443361\n",
      "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 0.409801\n",
      "Train Epoch: 3 [44160/60000 (74%)]\tLoss: 0.163742\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.175111\n",
      "Train Epoch: 3 [45440/60000 (76%)]\tLoss: 0.130700\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.294804\n",
      "Train Epoch: 3 [46720/60000 (78%)]\tLoss: 0.332329\n",
      "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 0.377497\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.433801\n",
      "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 0.272454\n",
      "Train Epoch: 3 [49280/60000 (82%)]\tLoss: 0.173602\n",
      "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 0.281055\n",
      "Train Epoch: 3 [50560/60000 (84%)]\tLoss: 0.167809\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.372823\n",
      "Train Epoch: 3 [51840/60000 (86%)]\tLoss: 0.339876\n",
      "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 0.189257\n",
      "Train Epoch: 3 [53120/60000 (88%)]\tLoss: 0.253362\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.324637\n",
      "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.448753\n",
      "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 0.167360\n",
      "Train Epoch: 3 [55680/60000 (93%)]\tLoss: 0.318607\n",
      "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 0.118204\n",
      "Train Epoch: 3 [56960/60000 (95%)]\tLoss: 0.483832\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.308111\n",
      "Train Epoch: 3 [58240/60000 (97%)]\tLoss: 0.402281\n",
      "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 0.138996\n",
      "Train Epoch: 3 [59520/60000 (99%)]\tLoss: 0.378711\n",
      "\n",
      "Test set: Avg. loss: 0.0873, Accuracy: 9717/10000 (97%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test()\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "  train(epoch)\n",
    "  test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-c73b301f3a92>:16: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0873, Accuracy: 9717/10000 (97%)\n",
      "\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.198599\n",
      "Train Epoch: 1 [640/60000 (1%)]\tLoss: 0.295066\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 0.232825\n",
      "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 0.259395\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 0.283609\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 0.410443\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 0.322180\n",
      "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 0.533285\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 0.257226\n",
      "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 0.296821\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.347618\n",
      "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 0.215266\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 0.175130\n",
      "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 0.301781\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 0.237409\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 0.100151\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 0.206028\n",
      "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 0.168561\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 0.277676\n",
      "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 0.117990\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.156877\n",
      "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 0.263676\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 0.287921\n",
      "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 0.158825\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 0.274673\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.286252\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 0.309304\n",
      "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 0.334158\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 0.358683\n",
      "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 0.337936\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.281982\n",
      "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 0.225221\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.272319\n",
      "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 0.182070\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 0.262642\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.328152\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.416751\n",
      "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 0.131912\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.137197\n",
      "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 0.205134\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.223196\n",
      "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 0.138949\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.342847\n",
      "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 0.311429\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.285272\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.245203\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.437181\n",
      "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 0.244404\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.272893\n",
      "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 0.228617\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.188929\n",
      "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 0.202399\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.230772\n",
      "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 0.153539\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.238769\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.254796\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.138764\n",
      "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 0.411415\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.257244\n",
      "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 0.120547\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.347272\n",
      "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 0.312799\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.260533\n",
      "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 0.397394\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.260317\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.161046\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.323476\n",
      "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 0.136814\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.107190\n",
      "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 0.206683\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.223522\n",
      "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 0.105612\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.361123\n",
      "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 0.303187\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.265783\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.329905\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.116085\n",
      "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 0.269301\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.178155\n",
      "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 0.151533\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.289380\n",
      "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 0.245824\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.203046\n",
      "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 0.099419\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.215218\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.237452\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.179058\n",
      "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 0.315291\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.263221\n",
      "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 0.105603\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.351089\n",
      "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 0.215902\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.274158\n",
      "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.223787\n",
      "\n",
      "Test set: Avg. loss: 0.0708, Accuracy: 9761/10000 (98%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.121663\n",
      "Train Epoch: 2 [640/60000 (1%)]\tLoss: 0.274826\n",
      "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 0.127311\n",
      "Train Epoch: 2 [1920/60000 (3%)]\tLoss: 0.240086\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 0.286068\n",
      "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.186013\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.328170\n",
      "Train Epoch: 2 [4480/60000 (7%)]\tLoss: 0.125876\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.173243\n",
      "Train Epoch: 2 [5760/60000 (10%)]\tLoss: 0.236153\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.160496\n",
      "Train Epoch: 2 [7040/60000 (12%)]\tLoss: 0.402605\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.424223\n",
      "Train Epoch: 2 [8320/60000 (14%)]\tLoss: 0.163837\n",
      "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.490117\n",
      "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.163481\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.130664\n",
      "Train Epoch: 2 [10880/60000 (18%)]\tLoss: 0.292286\n",
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.162033\n",
      "Train Epoch: 2 [12160/60000 (20%)]\tLoss: 0.262428\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.142426\n",
      "Train Epoch: 2 [13440/60000 (22%)]\tLoss: 0.161302\n",
      "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.111999\n",
      "Train Epoch: 2 [14720/60000 (25%)]\tLoss: 0.267985\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.215814\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.208891\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.416917\n",
      "Train Epoch: 2 [17280/60000 (29%)]\tLoss: 0.203166\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.327317\n",
      "Train Epoch: 2 [18560/60000 (31%)]\tLoss: 0.252848\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.350199\n",
      "Train Epoch: 2 [19840/60000 (33%)]\tLoss: 0.674870\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.336184\n",
      "Train Epoch: 2 [21120/60000 (35%)]\tLoss: 0.226634\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.192237\n",
      "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.196680\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.183050\n",
      "Train Epoch: 2 [23680/60000 (39%)]\tLoss: 0.136632\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 0.213503\n",
      "Train Epoch: 2 [24960/60000 (42%)]\tLoss: 0.284496\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.219393\n",
      "Train Epoch: 2 [26240/60000 (44%)]\tLoss: 0.225301\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.182106\n",
      "Train Epoch: 2 [27520/60000 (46%)]\tLoss: 0.293057\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.198513\n",
      "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.268400\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 0.331165\n",
      "Train Epoch: 2 [30080/60000 (50%)]\tLoss: 0.309367\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.241892\n",
      "Train Epoch: 2 [31360/60000 (52%)]\tLoss: 0.258203\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.218289\n",
      "Train Epoch: 2 [32640/60000 (54%)]\tLoss: 0.129565\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.228386\n",
      "Train Epoch: 2 [33920/60000 (57%)]\tLoss: 0.089361\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.151427\n",
      "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.204784\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.149274\n",
      "Train Epoch: 2 [36480/60000 (61%)]\tLoss: 0.303733\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.118840\n",
      "Train Epoch: 2 [37760/60000 (63%)]\tLoss: 0.127930\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.191193\n",
      "Train Epoch: 2 [39040/60000 (65%)]\tLoss: 0.131979\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.478954\n",
      "Train Epoch: 2 [40320/60000 (67%)]\tLoss: 0.175556\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.271872\n",
      "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.179657\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.175593\n",
      "Train Epoch: 2 [42880/60000 (71%)]\tLoss: 0.356259\n",
      "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 0.192383\n",
      "Train Epoch: 2 [44160/60000 (74%)]\tLoss: 0.088852\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.218604\n",
      "Train Epoch: 2 [45440/60000 (76%)]\tLoss: 0.210309\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.157056\n",
      "Train Epoch: 2 [46720/60000 (78%)]\tLoss: 0.340224\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.472065\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.159905\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.448467\n",
      "Train Epoch: 2 [49280/60000 (82%)]\tLoss: 0.492166\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.226238\n",
      "Train Epoch: 2 [50560/60000 (84%)]\tLoss: 0.090716\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.140738\n",
      "Train Epoch: 2 [51840/60000 (86%)]\tLoss: 0.226652\n",
      "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.127225\n",
      "Train Epoch: 2 [53120/60000 (88%)]\tLoss: 0.313639\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.102228\n",
      "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.240327\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.119692\n",
      "Train Epoch: 2 [55680/60000 (93%)]\tLoss: 0.229469\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.213890\n",
      "Train Epoch: 2 [56960/60000 (95%)]\tLoss: 0.118490\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.227451\n",
      "Train Epoch: 2 [58240/60000 (97%)]\tLoss: 0.182381\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.205538\n",
      "Train Epoch: 2 [59520/60000 (99%)]\tLoss: 0.382165\n",
      "\n",
      "Test set: Avg. loss: 0.0689, Accuracy: 9779/10000 (98%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.120579\n",
      "Train Epoch: 3 [640/60000 (1%)]\tLoss: 0.182127\n",
      "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 0.169208\n",
      "Train Epoch: 3 [1920/60000 (3%)]\tLoss: 0.369182\n",
      "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 0.160160\n",
      "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.106055\n",
      "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 0.087644\n",
      "Train Epoch: 3 [4480/60000 (7%)]\tLoss: 0.111358\n",
      "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 0.087535\n",
      "Train Epoch: 3 [5760/60000 (10%)]\tLoss: 0.136793\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.226593\n",
      "Train Epoch: 3 [7040/60000 (12%)]\tLoss: 0.244737\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.154194\n",
      "Train Epoch: 3 [8320/60000 (14%)]\tLoss: 0.468608\n",
      "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 0.246514\n",
      "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.317539\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.168649\n",
      "Train Epoch: 3 [10880/60000 (18%)]\tLoss: 0.181356\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 0.175595\n",
      "Train Epoch: 3 [12160/60000 (20%)]\tLoss: 0.474917\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.274037\n",
      "Train Epoch: 3 [13440/60000 (22%)]\tLoss: 0.281779\n",
      "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 0.153915\n",
      "Train Epoch: 3 [14720/60000 (25%)]\tLoss: 0.387389\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.203407\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.347070\n",
      "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 0.341739\n",
      "Train Epoch: 3 [17280/60000 (29%)]\tLoss: 0.369030\n",
      "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 0.354078\n",
      "Train Epoch: 3 [18560/60000 (31%)]\tLoss: 0.314133\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.288257\n",
      "Train Epoch: 3 [19840/60000 (33%)]\tLoss: 0.115008\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.194025\n",
      "Train Epoch: 3 [21120/60000 (35%)]\tLoss: 0.151223\n",
      "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 0.112330\n",
      "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.171198\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.131726\n",
      "Train Epoch: 3 [23680/60000 (39%)]\tLoss: 0.174660\n",
      "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 0.331520\n",
      "Train Epoch: 3 [24960/60000 (42%)]\tLoss: 0.416572\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.120170\n",
      "Train Epoch: 3 [26240/60000 (44%)]\tLoss: 0.172926\n",
      "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 0.138615\n",
      "Train Epoch: 3 [27520/60000 (46%)]\tLoss: 0.232325\n",
      "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 0.160575\n",
      "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.199494\n",
      "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 0.372560\n",
      "Train Epoch: 3 [30080/60000 (50%)]\tLoss: 0.227775\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.302669\n",
      "Train Epoch: 3 [31360/60000 (52%)]\tLoss: 0.134043\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.189457\n",
      "Train Epoch: 3 [32640/60000 (54%)]\tLoss: 0.197126\n",
      "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 0.319823\n",
      "Train Epoch: 3 [33920/60000 (57%)]\tLoss: 0.110265\n",
      "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 0.164448\n",
      "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 0.208332\n",
      "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 0.165770\n",
      "Train Epoch: 3 [36480/60000 (61%)]\tLoss: 0.154142\n",
      "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 0.150488\n",
      "Train Epoch: 3 [37760/60000 (63%)]\tLoss: 0.158641\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.184549\n",
      "Train Epoch: 3 [39040/60000 (65%)]\tLoss: 0.157542\n",
      "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 0.299476\n",
      "Train Epoch: 3 [40320/60000 (67%)]\tLoss: 0.193628\n",
      "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.115580\n",
      "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.596779\n",
      "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 0.265659\n",
      "Train Epoch: 3 [42880/60000 (71%)]\tLoss: 0.066201\n",
      "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 0.212314\n",
      "Train Epoch: 3 [44160/60000 (74%)]\tLoss: 0.313541\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.105482\n",
      "Train Epoch: 3 [45440/60000 (76%)]\tLoss: 0.066684\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.324110\n",
      "Train Epoch: 3 [46720/60000 (78%)]\tLoss: 0.103188\n",
      "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 0.241400\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.340079\n",
      "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 0.135040\n",
      "Train Epoch: 3 [49280/60000 (82%)]\tLoss: 0.240855\n",
      "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 0.425610\n",
      "Train Epoch: 3 [50560/60000 (84%)]\tLoss: 0.135806\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.186077\n",
      "Train Epoch: 3 [51840/60000 (86%)]\tLoss: 0.150989\n",
      "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 0.253332\n",
      "Train Epoch: 3 [53120/60000 (88%)]\tLoss: 0.195800\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.235839\n",
      "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.115224\n",
      "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 0.306552\n",
      "Train Epoch: 3 [55680/60000 (93%)]\tLoss: 0.180331\n",
      "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 0.401127\n",
      "Train Epoch: 3 [56960/60000 (95%)]\tLoss: 0.172900\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.312464\n",
      "Train Epoch: 3 [58240/60000 (97%)]\tLoss: 0.252527\n",
      "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 0.246865\n",
      "Train Epoch: 3 [59520/60000 (99%)]\tLoss: 0.282381\n",
      "\n",
      "Test set: Avg. loss: 0.0631, Accuracy: 9792/10000 (98%)\n",
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "test()\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "  train(epoch)\n",
    "  test()\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "plt.plot(train_counter, train_losses, color='blue')\n",
    "plt.scatter(test_counter, test_losses, color='red')\n",
    "plt.legend(['Train Loss', 'Test Loss'], loc='upper right')\n",
    "plt.xlabel('number of training examples seen')\n",
    "plt.ylabel('negative log likelihood loss')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "4d9defa72c2715dab9f7f172572cd30a1ab1a2083462d32ef96aadb7c6e0c73b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
